{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network\n",
    "\n",
    "dataset download link\n",
    "https://www.kaggle.com/chetankv/dogs-cats-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code is for limiting the GPU memory usage\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Preprocessing the Training set\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,  #Normalizing 0-1 \n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "# rescale shud be done for test, rest all should not be.\n",
    "# for train set we have to do all\n",
    "\n",
    "# creates some more images data -- Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# loading the training set\n",
    "training_set = train_datagen.flow_from_directory(r'E:\\ineuron\\DLCVNLP\\deeplearning\\CNN\\cats-dogs-main\\cat and dog dataset\\dataset\\train',\n",
    "                                                 target_size = (64, 64), #image size\n",
    "                                                 batch_size = 32,        \n",
    "                                                 class_mode = 'binary')  #(categorical)\n",
    "\n",
    "# Preprocessing the Test set\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "# only rescale thats it, nothing more. It can lead to overfitting.\n",
    "\n",
    "\n",
    "# loading the test set\n",
    "test_set = test_datagen.flow_from_directory(r'E:\\ineuron\\DLCVNLP\\deeplearning\\CNN\\cats-dogs-main\\cat and dog dataset\\dataset\\test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')    #(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Building the simple CNN\n",
    "\n",
    "# Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential()  #imp for forward & backward propagation\n",
    "\n",
    "# Step 1 - Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n",
    "\n",
    "# second Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Step 5 - Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  #(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,058,977\n",
      "Trainable params: 1,058,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters calculation for Conv2d layers\n",
    "\n",
    "number_parameters = out_channels * (in_channels * kernel_h * kernel_w + 1)  # 1 for bias  \n",
    "  \n",
    "in_channels = 3  \n",
    "out_channels = 32  \n",
    "kernel_h = kernel_w = 3  \n",
    "number_parameters = 32(3*3*3 + 1) = 896  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.6694 - accuracy: 0.5861 - val_loss: 0.6502 - val_accuracy: 0.6090\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 33s 134ms/step - loss: 0.6086 - accuracy: 0.6694 - val_loss: 0.6006 - val_accuracy: 0.6810\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 39s 156ms/step - loss: 0.5714 - accuracy: 0.7040 - val_loss: 0.5951 - val_accuracy: 0.6885\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.5452 - accuracy: 0.7211 - val_loss: 0.5397 - val_accuracy: 0.7450\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 38s 152ms/step - loss: 0.5226 - accuracy: 0.7424 - val_loss: 0.5146 - val_accuracy: 0.7420\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 39s 154ms/step - loss: 0.4977 - accuracy: 0.7569 - val_loss: 0.5216 - val_accuracy: 0.7460\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.4771 - accuracy: 0.7734 - val_loss: 0.4876 - val_accuracy: 0.7755\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.4655 - accuracy: 0.7771 - val_loss: 0.4853 - val_accuracy: 0.7690\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.4536 - accuracy: 0.7870 - val_loss: 0.4813 - val_accuracy: 0.7745\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.4264 - accuracy: 0.8018 - val_loss: 0.4904 - val_accuracy: 0.7775\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.4278 - accuracy: 0.8014 - val_loss: 0.4620 - val_accuracy: 0.7885\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.4191 - accuracy: 0.8070 - val_loss: 0.4609 - val_accuracy: 0.7945\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4088 - accuracy: 0.8177 - val_loss: 0.4469 - val_accuracy: 0.8035\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.3884 - accuracy: 0.8282 - val_loss: 0.4792 - val_accuracy: 0.7935\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.3881 - accuracy: 0.8257 - val_loss: 0.4629 - val_accuracy: 0.7970\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.3724 - accuracy: 0.8339 - val_loss: 0.4711 - val_accuracy: 0.7880\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.3693 - accuracy: 0.8349 - val_loss: 0.4600 - val_accuracy: 0.8040\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.3686 - accuracy: 0.8331 - val_loss: 0.4762 - val_accuracy: 0.7910\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.3505 - accuracy: 0.8409 - val_loss: 0.4586 - val_accuracy: 0.8060\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.3415 - accuracy: 0.8471 - val_loss: 0.4833 - val_accuracy: 0.7890\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.3307 - accuracy: 0.8514 - val_loss: 0.5276 - val_accuracy: 0.7730\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.3224 - accuracy: 0.8575 - val_loss: 0.4830 - val_accuracy: 0.8000\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.3131 - accuracy: 0.8680 - val_loss: 0.4551 - val_accuracy: 0.8050\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.3096 - accuracy: 0.8608 - val_loss: 0.4509 - val_accuracy: 0.8060\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.2896 - accuracy: 0.8733 - val_loss: 0.4625 - val_accuracy: 0.8045\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.2913 - accuracy: 0.8706 - val_loss: 0.4839 - val_accuracy: 0.8035\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.2741 - accuracy: 0.8815 - val_loss: 0.4706 - val_accuracy: 0.8060\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.2790 - accuracy: 0.8798 - val_loss: 0.5066 - val_accuracy: 0.7905\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.2624 - accuracy: 0.8880 - val_loss: 0.4829 - val_accuracy: 0.7960\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.2542 - accuracy: 0.8919 - val_loss: 0.5214 - val_accuracy: 0.7895\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.2463 - accuracy: 0.8971 - val_loss: 0.4845 - val_accuracy: 0.7970\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.2288 - accuracy: 0.9019 - val_loss: 0.5074 - val_accuracy: 0.8010\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.2401 - accuracy: 0.9013 - val_loss: 0.5243 - val_accuracy: 0.7850\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.2303 - accuracy: 0.9024 - val_loss: 0.5256 - val_accuracy: 0.7790\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.2170 - accuracy: 0.9105 - val_loss: 0.5287 - val_accuracy: 0.8135\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.2166 - accuracy: 0.9118 - val_loss: 0.5134 - val_accuracy: 0.7970\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.1978 - accuracy: 0.9200 - val_loss: 0.5143 - val_accuracy: 0.7980\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.2048 - accuracy: 0.9158 - val_loss: 0.5565 - val_accuracy: 0.8035\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.1892 - accuracy: 0.9200 - val_loss: 0.5724 - val_accuracy: 0.7920\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1820 - accuracy: 0.9235 - val_loss: 0.6231 - val_accuracy: 0.7800\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1856 - accuracy: 0.9252 - val_loss: 0.6456 - val_accuracy: 0.8010\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.1780 - accuracy: 0.9261 - val_loss: 0.5767 - val_accuracy: 0.8005\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1694 - accuracy: 0.9316 - val_loss: 0.5888 - val_accuracy: 0.7930\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.1733 - accuracy: 0.9301 - val_loss: 0.5956 - val_accuracy: 0.7925\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 41s 163ms/step - loss: 0.1623 - accuracy: 0.9350 - val_loss: 0.6056 - val_accuracy: 0.8065\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 34s 135ms/step - loss: 0.1573 - accuracy: 0.9370 - val_loss: 0.6453 - val_accuracy: 0.7920\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.1471 - accuracy: 0.9440 - val_loss: 0.6587 - val_accuracy: 0.7880\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 0.1495 - accuracy: 0.9391 - val_loss: 0.6353 - val_accuracy: 0.7970\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1451 - accuracy: 0.9446 - val_loss: 0.7138 - val_accuracy: 0.7815\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1415 - accuracy: 0.9424 - val_loss: 0.6616 - val_accuracy: 0.7985\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1327 - accuracy: 0.9501 - val_loss: 0.6427 - val_accuracy: 0.7955\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.1313 - accuracy: 0.9476 - val_loss: 0.6708 - val_accuracy: 0.7895\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1339 - accuracy: 0.9486 - val_loss: 0.6520 - val_accuracy: 0.8010\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1208 - accuracy: 0.9545 - val_loss: 0.6802 - val_accuracy: 0.8050\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1197 - accuracy: 0.9572 - val_loss: 0.7393 - val_accuracy: 0.7875\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1220 - accuracy: 0.9531 - val_loss: 0.7192 - val_accuracy: 0.7920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1136 - accuracy: 0.9560 - val_loss: 0.7140 - val_accuracy: 0.7940\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1147 - accuracy: 0.9553 - val_loss: 0.7364 - val_accuracy: 0.7965\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1094 - accuracy: 0.9590 - val_loss: 0.7738 - val_accuracy: 0.7870\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1100 - accuracy: 0.9584 - val_loss: 0.8420 - val_accuracy: 0.7805\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1108 - accuracy: 0.9581 - val_loss: 0.7999 - val_accuracy: 0.7835\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1109 - accuracy: 0.9576 - val_loss: 0.7498 - val_accuracy: 0.8035\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1084 - accuracy: 0.9588 - val_loss: 0.7465 - val_accuracy: 0.7990\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.1074 - accuracy: 0.9595 - val_loss: 0.8532 - val_accuracy: 0.7960\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1036 - accuracy: 0.9616 - val_loss: 0.8018 - val_accuracy: 0.8010\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0958 - accuracy: 0.9629 - val_loss: 0.8093 - val_accuracy: 0.7965\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0919 - accuracy: 0.9668 - val_loss: 0.8188 - val_accuracy: 0.7890\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0903 - accuracy: 0.9651 - val_loss: 0.7776 - val_accuracy: 0.7935\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1084 - accuracy: 0.9581 - val_loss: 0.7688 - val_accuracy: 0.8055\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0927 - accuracy: 0.9668 - val_loss: 0.8191 - val_accuracy: 0.7955\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0933 - accuracy: 0.9644 - val_loss: 0.9174 - val_accuracy: 0.7835\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0793 - accuracy: 0.9709 - val_loss: 0.8730 - val_accuracy: 0.8035\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0836 - accuracy: 0.9694 - val_loss: 0.8228 - val_accuracy: 0.8015\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0791 - accuracy: 0.9704 - val_loss: 0.8773 - val_accuracy: 0.7960\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0872 - accuracy: 0.9674 - val_loss: 0.9513 - val_accuracy: 0.7780\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0882 - accuracy: 0.9665 - val_loss: 0.8834 - val_accuracy: 0.8095\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0756 - accuracy: 0.9730 - val_loss: 0.9141 - val_accuracy: 0.8060\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0841 - accuracy: 0.9680 - val_loss: 0.8492 - val_accuracy: 0.7975\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0722 - accuracy: 0.9726 - val_loss: 0.9346 - val_accuracy: 0.7965\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0782 - accuracy: 0.9699 - val_loss: 0.9401 - val_accuracy: 0.8050\n",
      "Epoch 81/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0769 - accuracy: 0.9721 - val_loss: 0.8966 - val_accuracy: 0.7990\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0802 - accuracy: 0.9699 - val_loss: 0.8388 - val_accuracy: 0.8005\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0766 - accuracy: 0.9709 - val_loss: 0.8776 - val_accuracy: 0.7855\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0710 - accuracy: 0.9754 - val_loss: 0.8929 - val_accuracy: 0.8050\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0690 - accuracy: 0.9751 - val_loss: 0.8734 - val_accuracy: 0.8000\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0734 - accuracy: 0.9720 - val_loss: 0.9322 - val_accuracy: 0.7945\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0692 - accuracy: 0.9751 - val_loss: 0.8474 - val_accuracy: 0.8065\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 0.9142 - val_accuracy: 0.8090\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0629 - accuracy: 0.9770 - val_loss: 0.9400 - val_accuracy: 0.7965\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0653 - accuracy: 0.9753 - val_loss: 0.9808 - val_accuracy: 0.8000\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0826 - accuracy: 0.9704 - val_loss: 0.9611 - val_accuracy: 0.8080\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0767 - accuracy: 0.9718 - val_loss: 0.9640 - val_accuracy: 0.7915\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0677 - accuracy: 0.9743 - val_loss: 0.9579 - val_accuracy: 0.7975\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0740 - accuracy: 0.9726 - val_loss: 0.9422 - val_accuracy: 0.8060\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0743 - accuracy: 0.9729 - val_loss: 0.9619 - val_accuracy: 0.8000\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0595 - accuracy: 0.9797 - val_loss: 1.0640 - val_accuracy: 0.7905\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0654 - accuracy: 0.9749 - val_loss: 1.0112 - val_accuracy: 0.7915\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0644 - accuracy: 0.9772 - val_loss: 0.9556 - val_accuracy: 0.8130\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0600 - accuracy: 0.9781 - val_loss: 1.0317 - val_accuracy: 0.8020\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0580 - accuracy: 0.9780 - val_loss: 1.0228 - val_accuracy: 0.8025\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0622 - accuracy: 0.9783 - val_loss: 0.9929 - val_accuracy: 0.8010\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0695 - accuracy: 0.9760 - val_loss: 0.9326 - val_accuracy: 0.8065\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0559 - accuracy: 0.9806 - val_loss: 0.9268 - val_accuracy: 0.8145\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0567 - accuracy: 0.9785 - val_loss: 1.0262 - val_accuracy: 0.7955\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0574 - accuracy: 0.9790 - val_loss: 0.9859 - val_accuracy: 0.8080\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0579 - accuracy: 0.9795 - val_loss: 1.0710 - val_accuracy: 0.7905\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 1.1207 - val_accuracy: 0.7980\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0564 - accuracy: 0.9805 - val_loss: 1.0189 - val_accuracy: 0.8025\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0547 - accuracy: 0.9797 - val_loss: 1.1332 - val_accuracy: 0.7815\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0552 - accuracy: 0.9800 - val_loss: 1.0665 - val_accuracy: 0.8070\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0573 - accuracy: 0.9795 - val_loss: 1.0381 - val_accuracy: 0.8080\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0698 - accuracy: 0.9765 - val_loss: 1.0329 - val_accuracy: 0.7930\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 1.0555 - val_accuracy: 0.8055\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0483 - accuracy: 0.9835 - val_loss: 1.1153 - val_accuracy: 0.7995\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0582 - accuracy: 0.9803 - val_loss: 1.0783 - val_accuracy: 0.8080\n",
      "Epoch 116/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0613 - accuracy: 0.9793 - val_loss: 1.1255 - val_accuracy: 0.7855\n",
      "Epoch 117/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0596 - accuracy: 0.9790 - val_loss: 1.0636 - val_accuracy: 0.8095\n",
      "Epoch 118/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0508 - accuracy: 0.9822 - val_loss: 1.0560 - val_accuracy: 0.8015\n",
      "Epoch 119/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 1.0532 - val_accuracy: 0.8005\n",
      "Epoch 120/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 1.1123 - val_accuracy: 0.7945\n",
      "Epoch 121/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0538 - accuracy: 0.9804 - val_loss: 1.1025 - val_accuracy: 0.7980\n",
      "Epoch 122/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 1.1468 - val_accuracy: 0.8105\n",
      "Epoch 123/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 1.1619 - val_accuracy: 0.8005\n",
      "Epoch 124/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0468 - accuracy: 0.9833 - val_loss: 1.0946 - val_accuracy: 0.8005\n",
      "Epoch 125/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0491 - accuracy: 0.9833 - val_loss: 1.0770 - val_accuracy: 0.7985\n",
      "Epoch 126/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 1.1374 - val_accuracy: 0.8130\n",
      "Epoch 127/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0473 - accuracy: 0.9835 - val_loss: 1.0778 - val_accuracy: 0.8140\n",
      "Epoch 128/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 1.1228 - val_accuracy: 0.7980\n",
      "Epoch 129/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0388 - accuracy: 0.9851 - val_loss: 1.0598 - val_accuracy: 0.8080\n",
      "Epoch 130/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0531 - accuracy: 0.9812 - val_loss: 1.1459 - val_accuracy: 0.8060\n",
      "Epoch 131/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0552 - accuracy: 0.9834 - val_loss: 1.0455 - val_accuracy: 0.8035\n",
      "Epoch 132/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0446 - accuracy: 0.9844 - val_loss: 1.0379 - val_accuracy: 0.8125\n",
      "Epoch 133/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0530 - accuracy: 0.9796 - val_loss: 1.1046 - val_accuracy: 0.8060\n",
      "Epoch 134/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0448 - accuracy: 0.9845 - val_loss: 1.1585 - val_accuracy: 0.8080\n",
      "Epoch 135/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 1.1805 - val_accuracy: 0.7980\n",
      "Epoch 136/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0498 - accuracy: 0.9821 - val_loss: 1.1178 - val_accuracy: 0.8070\n",
      "Epoch 137/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0470 - accuracy: 0.9824 - val_loss: 1.1547 - val_accuracy: 0.7910\n",
      "Epoch 138/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 1.0811 - val_accuracy: 0.8035\n",
      "Epoch 139/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0558 - accuracy: 0.9825 - val_loss: 1.1011 - val_accuracy: 0.8115\n",
      "Epoch 140/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0535 - accuracy: 0.9797 - val_loss: 1.1652 - val_accuracy: 0.7990\n",
      "Epoch 141/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0492 - accuracy: 0.9833 - val_loss: 1.2257 - val_accuracy: 0.7935\n",
      "Epoch 142/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0348 - accuracy: 0.9877 - val_loss: 1.1497 - val_accuracy: 0.8005\n",
      "Epoch 143/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0404 - accuracy: 0.9868 - val_loss: 1.1905 - val_accuracy: 0.8090\n",
      "Epoch 144/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0526 - accuracy: 0.9821 - val_loss: 1.0515 - val_accuracy: 0.8060\n",
      "Epoch 145/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0464 - accuracy: 0.9831 - val_loss: 1.0885 - val_accuracy: 0.8030\n",
      "Epoch 146/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 1.2458 - val_accuracy: 0.7915\n",
      "Epoch 147/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0382 - accuracy: 0.9865 - val_loss: 1.2222 - val_accuracy: 0.8100\n",
      "Epoch 148/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: 1.1878 - val_accuracy: 0.8090\n",
      "Epoch 149/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0429 - accuracy: 0.9836 - val_loss: 1.1809 - val_accuracy: 0.8005\n",
      "Epoch 150/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 1.1101 - val_accuracy: 0.8085\n",
      "Epoch 151/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0417 - accuracy: 0.9859 - val_loss: 1.1222 - val_accuracy: 0.8155\n",
      "Epoch 152/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0387 - accuracy: 0.9865 - val_loss: 1.2030 - val_accuracy: 0.8040\n",
      "Epoch 153/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0496 - accuracy: 0.9824 - val_loss: 1.1614 - val_accuracy: 0.8045\n",
      "Epoch 154/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0369 - accuracy: 0.9875 - val_loss: 1.1511 - val_accuracy: 0.8115\n",
      "Epoch 155/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0496 - accuracy: 0.9859 - val_loss: 1.1583 - val_accuracy: 0.8070\n",
      "Epoch 156/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0378 - accuracy: 0.9854 - val_loss: 1.1600 - val_accuracy: 0.8055\n",
      "Epoch 157/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0482 - accuracy: 0.9834 - val_loss: 1.0364 - val_accuracy: 0.8170\n",
      "Epoch 158/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 1.0896 - val_accuracy: 0.8120\n",
      "Epoch 159/500\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 0.0363 - accuracy: 0.9868 - val_loss: 1.1229 - val_accuracy: 0.8090\n",
      "Epoch 160/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0460 - accuracy: 0.9854 - val_loss: 1.1738 - val_accuracy: 0.8045\n",
      "Epoch 161/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0455 - accuracy: 0.9849 - val_loss: 1.1926 - val_accuracy: 0.8085\n",
      "Epoch 162/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0366 - accuracy: 0.9868 - val_loss: 1.2116 - val_accuracy: 0.8045\n",
      "Epoch 163/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 1.2273 - val_accuracy: 0.8100\n",
      "Epoch 164/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 1.2047 - val_accuracy: 0.8015\n",
      "Epoch 165/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0361 - accuracy: 0.9864 - val_loss: 1.2291 - val_accuracy: 0.8015\n",
      "Epoch 166/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 1.2000 - val_accuracy: 0.8085\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0337 - accuracy: 0.9881 - val_loss: 1.2265 - val_accuracy: 0.8050\n",
      "Epoch 168/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0343 - accuracy: 0.9870 - val_loss: 1.1996 - val_accuracy: 0.8075\n",
      "Epoch 169/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 1.2899 - val_accuracy: 0.7970\n",
      "Epoch 170/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0327 - accuracy: 0.9886 - val_loss: 1.2608 - val_accuracy: 0.8045\n",
      "Epoch 171/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0427 - accuracy: 0.9849 - val_loss: 1.3677 - val_accuracy: 0.7985\n",
      "Epoch 172/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 1.2401 - val_accuracy: 0.8010\n",
      "Epoch 173/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 1.2799 - val_accuracy: 0.8005\n",
      "Epoch 174/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0419 - accuracy: 0.9850 - val_loss: 1.2240 - val_accuracy: 0.8005\n",
      "Epoch 175/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0394 - accuracy: 0.9851 - val_loss: 1.2548 - val_accuracy: 0.8040\n",
      "Epoch 176/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 1.2461 - val_accuracy: 0.8030\n",
      "Epoch 177/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 1.2714 - val_accuracy: 0.8020\n",
      "Epoch 178/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 1.3234 - val_accuracy: 0.7985\n",
      "Epoch 179/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 1.2385 - val_accuracy: 0.8080\n",
      "Epoch 180/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 1.2849 - val_accuracy: 0.8030\n",
      "Epoch 181/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 1.3482 - val_accuracy: 0.7980\n",
      "Epoch 182/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 1.4314 - val_accuracy: 0.7890\n",
      "Epoch 183/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 1.2552 - val_accuracy: 0.8070\n",
      "Epoch 184/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 1.2091 - val_accuracy: 0.8010\n",
      "Epoch 185/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 1.3719 - val_accuracy: 0.7945\n",
      "Epoch 186/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 1.2122 - val_accuracy: 0.8020\n",
      "Epoch 187/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 1.2375 - val_accuracy: 0.8060\n",
      "Epoch 188/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0309 - accuracy: 0.9884 - val_loss: 1.2629 - val_accuracy: 0.8020\n",
      "Epoch 189/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 1.3316 - val_accuracy: 0.8015\n",
      "Epoch 190/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 1.3521 - val_accuracy: 0.8115\n",
      "Epoch 191/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 1.2175 - val_accuracy: 0.8085\n",
      "Epoch 192/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0303 - accuracy: 0.9906 - val_loss: 1.2849 - val_accuracy: 0.8120\n",
      "Epoch 193/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0389 - accuracy: 0.9875 - val_loss: 1.2518 - val_accuracy: 0.8155\n",
      "Epoch 194/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0324 - accuracy: 0.9879 - val_loss: 1.2677 - val_accuracy: 0.8150\n",
      "Epoch 195/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 1.3184 - val_accuracy: 0.8030\n",
      "Epoch 196/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 1.3830 - val_accuracy: 0.8055\n",
      "Epoch 197/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0430 - accuracy: 0.9851 - val_loss: 1.3170 - val_accuracy: 0.8050\n",
      "Epoch 198/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0411 - accuracy: 0.9849 - val_loss: 1.2303 - val_accuracy: 0.8105\n",
      "Epoch 199/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0308 - accuracy: 0.9893 - val_loss: 1.2580 - val_accuracy: 0.8115\n",
      "Epoch 200/500\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 1.4038 - val_accuracy: 0.8010\n",
      "Epoch 201/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0341 - accuracy: 0.9879 - val_loss: 1.3272 - val_accuracy: 0.7995\n",
      "Epoch 202/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 1.3303 - val_accuracy: 0.8075\n",
      "Epoch 203/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 1.2963 - val_accuracy: 0.8085\n",
      "Epoch 204/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 1.2809 - val_accuracy: 0.8070\n",
      "Epoch 205/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 1.3551 - val_accuracy: 0.8080\n",
      "Epoch 206/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 1.3118 - val_accuracy: 0.8110\n",
      "Epoch 207/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 1.3560 - val_accuracy: 0.8045\n",
      "Epoch 208/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0247 - accuracy: 0.9906 - val_loss: 1.3674 - val_accuracy: 0.7990\n",
      "Epoch 209/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0349 - accuracy: 0.9871 - val_loss: 1.3561 - val_accuracy: 0.8020\n",
      "Epoch 210/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 1.3029 - val_accuracy: 0.8085\n",
      "Epoch 211/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0337 - accuracy: 0.9875 - val_loss: 1.2787 - val_accuracy: 0.8075\n",
      "Epoch 212/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0326 - accuracy: 0.9889 - val_loss: 1.2736 - val_accuracy: 0.8065\n",
      "Epoch 213/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0392 - accuracy: 0.9855 - val_loss: 1.2425 - val_accuracy: 0.8045\n",
      "Epoch 214/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 1.3300 - val_accuracy: 0.8150\n",
      "Epoch 215/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0300 - accuracy: 0.9902 - val_loss: 1.4472 - val_accuracy: 0.7990\n",
      "Epoch 216/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 1.3528 - val_accuracy: 0.8110\n",
      "Epoch 217/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 1.3521 - val_accuracy: 0.8010\n",
      "Epoch 218/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 1.3097 - val_accuracy: 0.8135\n",
      "Epoch 219/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0303 - accuracy: 0.9886 - val_loss: 1.4739 - val_accuracy: 0.8005\n",
      "Epoch 220/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0242 - accuracy: 0.9910 - val_loss: 1.3563 - val_accuracy: 0.8025\n",
      "Epoch 221/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 1.4052 - val_accuracy: 0.7965\n",
      "Epoch 222/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 1.3573 - val_accuracy: 0.8120\n",
      "Epoch 223/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0381 - accuracy: 0.9874 - val_loss: 1.4024 - val_accuracy: 0.8055\n",
      "Epoch 224/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 1.2680 - val_accuracy: 0.8115\n",
      "Epoch 225/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0270 - accuracy: 0.9901 - val_loss: 1.2860 - val_accuracy: 0.8160\n",
      "Epoch 226/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 1.3101 - val_accuracy: 0.8065\n",
      "Epoch 227/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 1.3466 - val_accuracy: 0.8075\n",
      "Epoch 228/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 1.3505 - val_accuracy: 0.8055\n",
      "Epoch 229/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 1.4759 - val_accuracy: 0.7955\n",
      "Epoch 230/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0288 - accuracy: 0.9902 - val_loss: 1.5178 - val_accuracy: 0.8035\n",
      "Epoch 231/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 1.4228 - val_accuracy: 0.8055\n",
      "Epoch 232/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 1.4347 - val_accuracy: 0.8005\n",
      "Epoch 233/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 1.3842 - val_accuracy: 0.8100\n",
      "Epoch 234/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0345 - accuracy: 0.9875 - val_loss: 1.2705 - val_accuracy: 0.8010\n",
      "Epoch 235/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 1.3695 - val_accuracy: 0.8025\n",
      "Epoch 236/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 1.3765 - val_accuracy: 0.8060\n",
      "Epoch 237/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0272 - accuracy: 0.9891 - val_loss: 1.3535 - val_accuracy: 0.8000\n",
      "Epoch 238/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0245 - accuracy: 0.9906 - val_loss: 1.3993 - val_accuracy: 0.8115\n",
      "Epoch 239/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 1.3788 - val_accuracy: 0.8090\n",
      "Epoch 240/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 1.4078 - val_accuracy: 0.8045\n",
      "Epoch 241/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 1.3456 - val_accuracy: 0.8055\n",
      "Epoch 242/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0211 - accuracy: 0.9921 - val_loss: 1.3290 - val_accuracy: 0.8090\n",
      "Epoch 243/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 1.3830 - val_accuracy: 0.8155\n",
      "Epoch 244/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0256 - accuracy: 0.9923 - val_loss: 1.3887 - val_accuracy: 0.7995\n",
      "Epoch 245/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0330 - accuracy: 0.9883 - val_loss: 1.4493 - val_accuracy: 0.8090\n",
      "Epoch 246/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 1.4704 - val_accuracy: 0.7960\n",
      "Epoch 247/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 1.3005 - val_accuracy: 0.8065\n",
      "Epoch 248/500\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 1.3794 - val_accuracy: 0.8035\n",
      "Epoch 249/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0242 - accuracy: 0.9906 - val_loss: 1.4660 - val_accuracy: 0.8110\n",
      "Epoch 250/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 1.4554 - val_accuracy: 0.8080\n",
      "Epoch 251/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 1.3402 - val_accuracy: 0.8025\n",
      "Epoch 252/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 1.3799 - val_accuracy: 0.8025\n",
      "Epoch 253/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0226 - accuracy: 0.9918 - val_loss: 1.4909 - val_accuracy: 0.8100\n",
      "Epoch 254/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 1.4852 - val_accuracy: 0.8005\n",
      "Epoch 255/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 1.4435 - val_accuracy: 0.7995\n",
      "Epoch 256/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 1.4512 - val_accuracy: 0.7985\n",
      "Epoch 257/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 1.4346 - val_accuracy: 0.8105\n",
      "Epoch 258/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 1.3720 - val_accuracy: 0.8130\n",
      "Epoch 259/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0248 - accuracy: 0.9906 - val_loss: 1.4589 - val_accuracy: 0.8050\n",
      "Epoch 260/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 1.4879 - val_accuracy: 0.8090\n",
      "Epoch 261/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 1.4099 - val_accuracy: 0.8050\n",
      "Epoch 262/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 1.4658 - val_accuracy: 0.8005\n",
      "Epoch 263/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0231 - accuracy: 0.9923 - val_loss: 1.4542 - val_accuracy: 0.8105\n",
      "Epoch 264/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 1.4766 - val_accuracy: 0.8075\n",
      "Epoch 265/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 1.3985 - val_accuracy: 0.8110\n",
      "Epoch 266/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 1.5392 - val_accuracy: 0.8015\n",
      "Epoch 267/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0361 - accuracy: 0.9881 - val_loss: 1.3728 - val_accuracy: 0.8075\n",
      "Epoch 268/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0266 - accuracy: 0.9899 - val_loss: 1.3612 - val_accuracy: 0.8035\n",
      "Epoch 269/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 1.3792 - val_accuracy: 0.7980\n",
      "Epoch 270/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 1.3593 - val_accuracy: 0.8015\n",
      "Epoch 271/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0195 - accuracy: 0.9930 - val_loss: 1.3929 - val_accuracy: 0.8005\n",
      "Epoch 272/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 1.4736 - val_accuracy: 0.8000\n",
      "Epoch 273/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0231 - accuracy: 0.9919 - val_loss: 1.4610 - val_accuracy: 0.7945\n",
      "Epoch 274/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 1.4505 - val_accuracy: 0.7960\n",
      "Epoch 275/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 1.4568 - val_accuracy: 0.7965\n",
      "Epoch 276/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 1.4152 - val_accuracy: 0.8050\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 1.3971 - val_accuracy: 0.8065\n",
      "Epoch 278/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 1.3732 - val_accuracy: 0.8045\n",
      "Epoch 279/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 1.2802 - val_accuracy: 0.8055\n",
      "Epoch 280/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0163 - accuracy: 0.9939 - val_loss: 1.3991 - val_accuracy: 0.8115\n",
      "Epoch 281/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 1.5553 - val_accuracy: 0.7970\n",
      "Epoch 282/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 1.5234 - val_accuracy: 0.7985\n",
      "Epoch 283/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 1.4262 - val_accuracy: 0.8075\n",
      "Epoch 284/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 1.5062 - val_accuracy: 0.8095\n",
      "Epoch 285/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 1.4432 - val_accuracy: 0.8005\n",
      "Epoch 286/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 1.4298 - val_accuracy: 0.8020\n",
      "Epoch 287/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 1.5386 - val_accuracy: 0.7935\n",
      "Epoch 288/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 1.5114 - val_accuracy: 0.7995\n",
      "Epoch 289/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0222 - accuracy: 0.9919 - val_loss: 1.5326 - val_accuracy: 0.8115\n",
      "Epoch 290/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0211 - accuracy: 0.9941 - val_loss: 1.4895 - val_accuracy: 0.8045\n",
      "Epoch 291/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 1.5774 - val_accuracy: 0.8080\n",
      "Epoch 292/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0272 - accuracy: 0.9901 - val_loss: 1.5176 - val_accuracy: 0.8075\n",
      "Epoch 293/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 1.5387 - val_accuracy: 0.8110\n",
      "Epoch 294/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 1.5292 - val_accuracy: 0.8080\n",
      "Epoch 295/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 1.4875 - val_accuracy: 0.8065\n",
      "Epoch 296/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 1.4548 - val_accuracy: 0.8080\n",
      "Epoch 297/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 1.4924 - val_accuracy: 0.8045\n",
      "Epoch 298/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 1.5023 - val_accuracy: 0.8025\n",
      "Epoch 299/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 1.4392 - val_accuracy: 0.8085\n",
      "Epoch 300/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0238 - accuracy: 0.9920 - val_loss: 1.4311 - val_accuracy: 0.8110\n",
      "Epoch 301/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 1.4806 - val_accuracy: 0.8055\n",
      "Epoch 302/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 1.4861 - val_accuracy: 0.8110\n",
      "Epoch 303/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 1.4075 - val_accuracy: 0.8075\n",
      "Epoch 304/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 1.4798 - val_accuracy: 0.8065\n",
      "Epoch 305/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0187 - accuracy: 0.9931 - val_loss: 1.3907 - val_accuracy: 0.8150\n",
      "Epoch 306/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 1.4430 - val_accuracy: 0.8110\n",
      "Epoch 307/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 1.5041 - val_accuracy: 0.8095\n",
      "Epoch 308/500\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 1.4379 - val_accuracy: 0.8095\n",
      "Epoch 309/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 1.4126 - val_accuracy: 0.8070\n",
      "Epoch 310/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 1.5554 - val_accuracy: 0.7950\n",
      "Epoch 311/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 1.5084 - val_accuracy: 0.8140\n",
      "Epoch 312/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 1.4799 - val_accuracy: 0.8055\n",
      "Epoch 313/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 1.5379 - val_accuracy: 0.8070\n",
      "Epoch 314/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 1.4727 - val_accuracy: 0.8120\n",
      "Epoch 315/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 1.5025 - val_accuracy: 0.8090\n",
      "Epoch 316/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 1.5156 - val_accuracy: 0.7995\n",
      "Epoch 317/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 1.5205 - val_accuracy: 0.8035\n",
      "Epoch 318/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 1.5911 - val_accuracy: 0.7990\n",
      "Epoch 319/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 1.5339 - val_accuracy: 0.7950\n",
      "Epoch 320/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 1.3865 - val_accuracy: 0.8095\n",
      "Epoch 321/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 1.5351 - val_accuracy: 0.8115\n",
      "Epoch 322/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 1.6775 - val_accuracy: 0.7970\n",
      "Epoch 323/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 1.5933 - val_accuracy: 0.8050\n",
      "Epoch 324/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 1.6397 - val_accuracy: 0.7920\n",
      "Epoch 325/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 1.5096 - val_accuracy: 0.8055\n",
      "Epoch 326/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 1.4779 - val_accuracy: 0.8115\n",
      "Epoch 327/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 1.5761 - val_accuracy: 0.8040\n",
      "Epoch 328/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 1.4565 - val_accuracy: 0.8035\n",
      "Epoch 329/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 1.4425 - val_accuracy: 0.7990\n",
      "Epoch 330/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 1.5825 - val_accuracy: 0.8055\n",
      "Epoch 331/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 1.4654 - val_accuracy: 0.8015\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 1.5070 - val_accuracy: 0.8050\n",
      "Epoch 333/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 1.5873 - val_accuracy: 0.7900\n",
      "Epoch 334/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 1.4152 - val_accuracy: 0.8090\n",
      "Epoch 335/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 1.5662 - val_accuracy: 0.7990\n",
      "Epoch 336/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 1.4855 - val_accuracy: 0.7955\n",
      "Epoch 337/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0173 - accuracy: 0.9936 - val_loss: 1.4287 - val_accuracy: 0.8085\n",
      "Epoch 338/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 1.5965 - val_accuracy: 0.8015\n",
      "Epoch 339/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 1.5273 - val_accuracy: 0.7995\n",
      "Epoch 340/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 1.6060 - val_accuracy: 0.8040\n",
      "Epoch 341/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 1.5498 - val_accuracy: 0.8030\n",
      "Epoch 342/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 1.6879 - val_accuracy: 0.8060\n",
      "Epoch 343/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0236 - accuracy: 0.9909 - val_loss: 1.5459 - val_accuracy: 0.7940\n",
      "Epoch 344/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 1.5867 - val_accuracy: 0.8055\n",
      "Epoch 345/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 1.4746 - val_accuracy: 0.8040\n",
      "Epoch 346/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 1.5981 - val_accuracy: 0.8010\n",
      "Epoch 347/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 1.5228 - val_accuracy: 0.7910\n",
      "Epoch 348/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0200 - accuracy: 0.9920 - val_loss: 1.4481 - val_accuracy: 0.8120\n",
      "Epoch 349/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.4474 - val_accuracy: 0.8155\n",
      "Epoch 350/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0154 - accuracy: 0.9941 - val_loss: 1.5162 - val_accuracy: 0.7965\n",
      "Epoch 351/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 1.4634 - val_accuracy: 0.8065\n",
      "Epoch 352/500\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 1.4565 - val_accuracy: 0.8120\n",
      "Epoch 353/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 1.5196 - val_accuracy: 0.8030\n",
      "Epoch 354/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 1.5672 - val_accuracy: 0.8045\n",
      "Epoch 355/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0168 - accuracy: 0.9941 - val_loss: 1.5084 - val_accuracy: 0.8055\n",
      "Epoch 356/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 1.6409 - val_accuracy: 0.8005\n",
      "Epoch 357/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 1.4817 - val_accuracy: 0.8125\n",
      "Epoch 358/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 1.7602 - val_accuracy: 0.7930\n",
      "Epoch 359/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 1.5659 - val_accuracy: 0.8040\n",
      "Epoch 360/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 1.5098 - val_accuracy: 0.8115\n",
      "Epoch 361/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0238 - accuracy: 0.9929 - val_loss: 1.5456 - val_accuracy: 0.8050\n",
      "Epoch 362/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 1.5217 - val_accuracy: 0.8110\n",
      "Epoch 363/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 1.5622 - val_accuracy: 0.8090\n",
      "Epoch 364/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 1.6097 - val_accuracy: 0.8115\n",
      "Epoch 365/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 1.5771 - val_accuracy: 0.8075\n",
      "Epoch 366/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 1.6170 - val_accuracy: 0.8055\n",
      "Epoch 367/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 1.5709 - val_accuracy: 0.8010\n",
      "Epoch 368/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 1.6123 - val_accuracy: 0.8065\n",
      "Epoch 369/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 1.6950 - val_accuracy: 0.7965\n",
      "Epoch 370/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 1.5943 - val_accuracy: 0.8070\n",
      "Epoch 371/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 1.6593 - val_accuracy: 0.8065\n",
      "Epoch 372/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 1.9371 - val_accuracy: 0.7860\n",
      "Epoch 373/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 1.6790 - val_accuracy: 0.7990\n",
      "Epoch 374/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 1.5983 - val_accuracy: 0.8070\n",
      "Epoch 375/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0164 - accuracy: 0.9935 - val_loss: 1.6837 - val_accuracy: 0.8015\n",
      "Epoch 376/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 1.6168 - val_accuracy: 0.8085\n",
      "Epoch 377/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 1.5765 - val_accuracy: 0.8015\n",
      "Epoch 378/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 1.5906 - val_accuracy: 0.8065\n",
      "Epoch 379/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0153 - accuracy: 0.9945 - val_loss: 1.6222 - val_accuracy: 0.8115\n",
      "Epoch 380/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 1.7100 - val_accuracy: 0.8015\n",
      "Epoch 381/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 1.6415 - val_accuracy: 0.8020\n",
      "Epoch 382/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0191 - accuracy: 0.9934 - val_loss: 1.6245 - val_accuracy: 0.7970\n",
      "Epoch 383/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 1.5859 - val_accuracy: 0.8075\n",
      "Epoch 384/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 1.6696 - val_accuracy: 0.8110\n",
      "Epoch 385/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 1.5936 - val_accuracy: 0.8185\n",
      "Epoch 386/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0150 - accuracy: 0.9944 - val_loss: 1.6152 - val_accuracy: 0.8040\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 1.6661 - val_accuracy: 0.7990\n",
      "Epoch 388/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 1.6635 - val_accuracy: 0.8010\n",
      "Epoch 389/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 1.6830 - val_accuracy: 0.8050\n",
      "Epoch 390/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 1.6663 - val_accuracy: 0.8030\n",
      "Epoch 391/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 1.6005 - val_accuracy: 0.8075\n",
      "Epoch 392/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 1.5929 - val_accuracy: 0.8145\n",
      "Epoch 393/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 1.7300 - val_accuracy: 0.8095\n",
      "Epoch 394/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.6691 - val_accuracy: 0.8165\n",
      "Epoch 395/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 1.5756 - val_accuracy: 0.8110\n",
      "Epoch 396/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 1.6689 - val_accuracy: 0.8030\n",
      "Epoch 397/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 1.7081 - val_accuracy: 0.8035\n",
      "Epoch 398/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 1.5564 - val_accuracy: 0.8055\n",
      "Epoch 399/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0260 - accuracy: 0.9927 - val_loss: 1.7404 - val_accuracy: 0.7910\n",
      "Epoch 400/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 1.5013 - val_accuracy: 0.8095\n",
      "Epoch 401/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 1.6584 - val_accuracy: 0.7965\n",
      "Epoch 402/500\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 1.7256 - val_accuracy: 0.8005\n",
      "Epoch 403/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 1.4724 - val_accuracy: 0.8050\n",
      "Epoch 404/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0149 - accuracy: 0.9940 - val_loss: 1.6670 - val_accuracy: 0.8075\n",
      "Epoch 405/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 1.6542 - val_accuracy: 0.8085\n",
      "Epoch 406/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 1.7272 - val_accuracy: 0.8105\n",
      "Epoch 407/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 1.6534 - val_accuracy: 0.7970\n",
      "Epoch 408/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 1.5932 - val_accuracy: 0.8150\n",
      "Epoch 409/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 1.5876 - val_accuracy: 0.8150\n",
      "Epoch 410/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0244 - accuracy: 0.9934 - val_loss: 1.7128 - val_accuracy: 0.7970\n",
      "Epoch 411/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.5092 - val_accuracy: 0.8130\n",
      "Epoch 412/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.5487 - val_accuracy: 0.8070\n",
      "Epoch 413/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 1.5829 - val_accuracy: 0.8065\n",
      "Epoch 414/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0101 - accuracy: 0.9962 - val_loss: 1.6054 - val_accuracy: 0.8140\n",
      "Epoch 415/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 1.8131 - val_accuracy: 0.8040\n",
      "Epoch 416/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0114 - accuracy: 0.9952 - val_loss: 1.7354 - val_accuracy: 0.8105\n",
      "Epoch 417/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 1.9583 - val_accuracy: 0.7980\n",
      "Epoch 418/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0217 - accuracy: 0.9924 - val_loss: 1.6103 - val_accuracy: 0.8050\n",
      "Epoch 419/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 1.6352 - val_accuracy: 0.8060\n",
      "Epoch 420/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 1.7308 - val_accuracy: 0.8065\n",
      "Epoch 421/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 1.6216 - val_accuracy: 0.8070\n",
      "Epoch 422/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 1.5883 - val_accuracy: 0.8120\n",
      "Epoch 423/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0140 - accuracy: 0.9959 - val_loss: 1.5693 - val_accuracy: 0.8050\n",
      "Epoch 424/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.6789 - val_accuracy: 0.8035\n",
      "Epoch 425/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 1.5391 - val_accuracy: 0.8095\n",
      "Epoch 426/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0181 - accuracy: 0.9935 - val_loss: 1.5947 - val_accuracy: 0.7940\n",
      "Epoch 427/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 1.5747 - val_accuracy: 0.8055\n",
      "Epoch 428/500\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 1.7688 - val_accuracy: 0.7850\n",
      "Epoch 429/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0126 - accuracy: 0.9952 - val_loss: 1.6136 - val_accuracy: 0.8115\n",
      "Epoch 430/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 1.6225 - val_accuracy: 0.7965\n",
      "Epoch 431/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 1.5182 - val_accuracy: 0.8095\n",
      "Epoch 432/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 1.7219 - val_accuracy: 0.8020\n",
      "Epoch 433/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 1.6300 - val_accuracy: 0.8120\n",
      "Epoch 434/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0177 - accuracy: 0.9936 - val_loss: 1.5910 - val_accuracy: 0.8140\n",
      "Epoch 435/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 1.6163 - val_accuracy: 0.8025\n",
      "Epoch 436/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 1.5611 - val_accuracy: 0.8110\n",
      "Epoch 437/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 1.5510 - val_accuracy: 0.8190\n",
      "Epoch 438/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 1.6354 - val_accuracy: 0.8045\n",
      "Epoch 439/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 1.6174 - val_accuracy: 0.8085\n",
      "Epoch 440/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 1.6141 - val_accuracy: 0.7995\n",
      "Epoch 441/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 1.8387 - val_accuracy: 0.7880\n",
      "Epoch 442/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 1.6448 - val_accuracy: 0.8070\n",
      "Epoch 443/500\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 0.0210 - accuracy: 0.9934 - val_loss: 1.6633 - val_accuracy: 0.8115\n",
      "Epoch 444/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 1.5985 - val_accuracy: 0.8105\n",
      "Epoch 445/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 1.7506 - val_accuracy: 0.8150\n",
      "Epoch 446/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 1.5545 - val_accuracy: 0.8135\n",
      "Epoch 447/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 1.6265 - val_accuracy: 0.8080\n",
      "Epoch 448/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 1.6361 - val_accuracy: 0.8140\n",
      "Epoch 449/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 1.6387 - val_accuracy: 0.8085\n",
      "Epoch 450/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.6466 - val_accuracy: 0.8150\n",
      "Epoch 451/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 1.5449 - val_accuracy: 0.8120\n",
      "Epoch 452/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 1.6581 - val_accuracy: 0.8090\n",
      "Epoch 453/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 1.6971 - val_accuracy: 0.8110\n",
      "Epoch 454/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 1.6725 - val_accuracy: 0.8075\n",
      "Epoch 455/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 1.6206 - val_accuracy: 0.8025\n",
      "Epoch 456/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 1.6947 - val_accuracy: 0.8105\n",
      "Epoch 457/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0178 - accuracy: 0.9952 - val_loss: 1.6735 - val_accuracy: 0.8115\n",
      "Epoch 458/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 1.7797 - val_accuracy: 0.7950\n",
      "Epoch 459/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 1.6640 - val_accuracy: 0.8085\n",
      "Epoch 460/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 1.7289 - val_accuracy: 0.8070\n",
      "Epoch 461/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.6796 - val_accuracy: 0.8035\n",
      "Epoch 462/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 1.5187 - val_accuracy: 0.8075\n",
      "Epoch 463/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 1.6693 - val_accuracy: 0.8100\n",
      "Epoch 464/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 1.5863 - val_accuracy: 0.8130\n",
      "Epoch 465/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 1.6652 - val_accuracy: 0.8080\n",
      "Epoch 466/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 1.8064 - val_accuracy: 0.8040\n",
      "Epoch 467/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 1.5980 - val_accuracy: 0.8035\n",
      "Epoch 468/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 1.6700 - val_accuracy: 0.8050\n",
      "Epoch 469/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 1.5963 - val_accuracy: 0.8080\n",
      "Epoch 470/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 1.7829 - val_accuracy: 0.8015\n",
      "Epoch 471/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 1.7128 - val_accuracy: 0.7990\n",
      "Epoch 472/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 1.6922 - val_accuracy: 0.8020\n",
      "Epoch 473/500\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 1.7662 - val_accuracy: 0.8100\n",
      "Epoch 474/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 1.6096 - val_accuracy: 0.8045\n",
      "Epoch 475/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 1.5469 - val_accuracy: 0.8045\n",
      "Epoch 476/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 1.5177 - val_accuracy: 0.8145\n",
      "Epoch 477/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 1.6048 - val_accuracy: 0.8000\n",
      "Epoch 478/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 1.6528 - val_accuracy: 0.8035\n",
      "Epoch 479/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 1.6273 - val_accuracy: 0.8095\n",
      "Epoch 480/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 1.6971 - val_accuracy: 0.7975\n",
      "Epoch 481/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 1.7473 - val_accuracy: 0.7960\n",
      "Epoch 482/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 1.6513 - val_accuracy: 0.8050\n",
      "Epoch 483/500\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 1.8054 - val_accuracy: 0.8170\n",
      "Epoch 484/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.6857 - val_accuracy: 0.7985\n",
      "Epoch 485/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 1.8352 - val_accuracy: 0.7920\n",
      "Epoch 486/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 1.6601 - val_accuracy: 0.8035\n",
      "Epoch 487/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 1.6319 - val_accuracy: 0.8085\n",
      "Epoch 488/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 1.5516 - val_accuracy: 0.8090\n",
      "Epoch 489/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 1.6123 - val_accuracy: 0.8050\n",
      "Epoch 490/500\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 1.5820 - val_accuracy: 0.8075\n",
      "Epoch 491/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 1.6969 - val_accuracy: 0.8055\n",
      "Epoch 492/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.7299 - val_accuracy: 0.7985\n",
      "Epoch 493/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 1.6958 - val_accuracy: 0.8060\n",
      "Epoch 494/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 1.8020 - val_accuracy: 0.7975\n",
      "Epoch 495/500\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 1.5640 - val_accuracy: 0.7950\n",
      "Epoch 496/500\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 1.6666 - val_accuracy: 0.8175\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 1.6156 - val_accuracy: 0.8140\n",
      "Epoch 498/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.7070 - val_accuracy: 0.8070\n",
      "Epoch 499/500\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 1.7128 - val_accuracy: 0.8060\n",
      "Epoch 500/500\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 1.7046 - val_accuracy: 0.8005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cf3239f4e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3 - Training the CNN\n",
    "\n",
    "# Compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "                                  # categorical_crossentropy\n",
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a h5 file\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn.save('model_rcat_dog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('model_rcat_dog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1048704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,058,977\n",
      "Trainable params: 1,058,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4 - Making a single prediction\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img(r'E:\\ineuron\\DLCVNLP\\deeplearning\\CNN\\cats-dogs-main\\cat and dog dataset\\dataset\\test\\cats\\cat.4123.jpg', target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image=test_image/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.6209383e-13]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image classified is cat\n"
     ]
    }
   ],
   "source": [
    "if result[0]<=0.5:\n",
    "    print(\"The image classified is cat\")\n",
    "else:\n",
    "    print(\"The image classified is dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x2CF9AD57940>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.load_img(r'E:\\ineuron\\DLCVNLP\\deeplearning\\CNN\\cats-dogs-main\\cat and dog dataset\\dataset\\test\\dogs\\dog.4163.jpg', target_size = (64,64))\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[232., 211., 184.],\n",
       "        [219., 199., 172.],\n",
       "        [191., 161., 137.],\n",
       "        ...,\n",
       "        [145., 125., 100.],\n",
       "        [196., 175., 148.],\n",
       "        [197., 176., 149.]],\n",
       "\n",
       "       [[230., 209., 182.],\n",
       "        [212., 192., 165.],\n",
       "        [200., 170., 146.],\n",
       "        ...,\n",
       "        [166., 146., 121.],\n",
       "        [191., 170., 143.],\n",
       "        [214., 193., 166.]],\n",
       "\n",
       "       [[233., 212., 185.],\n",
       "        [209., 189., 162.],\n",
       "        [209., 179., 155.],\n",
       "        ...,\n",
       "        [187., 167., 142.],\n",
       "        [203., 182., 155.],\n",
       "        [204., 183., 156.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[213., 178., 140.],\n",
       "        [195., 160., 122.],\n",
       "        [179., 144., 106.],\n",
       "        ...,\n",
       "        [134., 108.,  75.],\n",
       "        [170., 146., 112.],\n",
       "        [194., 170., 136.]],\n",
       "\n",
       "       [[212., 174., 129.],\n",
       "        [210., 171., 130.],\n",
       "        [166., 134.,  93.],\n",
       "        ...,\n",
       "        [146., 118.,  81.],\n",
       "        [153., 125.,  88.],\n",
       "        [148., 119.,  87.]],\n",
       "\n",
       "       [[199., 161., 116.],\n",
       "        [209., 170., 129.],\n",
       "        [172., 140.,  99.],\n",
       "        ...,\n",
       "        [145., 115.,  77.],\n",
       "        [149., 119.,  83.],\n",
       "        [160., 129.,  98.]]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = image.img_to_array(test_image)\n",
    "print(test_image.shape)\n",
    "test_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.9098039 , 0.827451  , 0.72156864],\n",
       "        [0.85882354, 0.78039217, 0.6745098 ],\n",
       "        [0.7490196 , 0.6313726 , 0.5372549 ],\n",
       "        ...,\n",
       "        [0.5686275 , 0.49019608, 0.39215687],\n",
       "        [0.76862746, 0.6862745 , 0.5803922 ],\n",
       "        [0.77254903, 0.6901961 , 0.58431375]],\n",
       "\n",
       "       [[0.9019608 , 0.81960785, 0.7137255 ],\n",
       "        [0.83137256, 0.7529412 , 0.64705884],\n",
       "        [0.78431374, 0.6666667 , 0.57254905],\n",
       "        ...,\n",
       "        [0.6509804 , 0.57254905, 0.4745098 ],\n",
       "        [0.7490196 , 0.6666667 , 0.56078434],\n",
       "        [0.8392157 , 0.75686276, 0.6509804 ]],\n",
       "\n",
       "       [[0.9137255 , 0.83137256, 0.7254902 ],\n",
       "        [0.81960785, 0.7411765 , 0.63529414],\n",
       "        [0.81960785, 0.7019608 , 0.60784316],\n",
       "        ...,\n",
       "        [0.73333335, 0.654902  , 0.5568628 ],\n",
       "        [0.79607844, 0.7137255 , 0.60784316],\n",
       "        [0.8       , 0.7176471 , 0.6117647 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.8352941 , 0.69803923, 0.54901963],\n",
       "        [0.7647059 , 0.627451  , 0.47843137],\n",
       "        [0.7019608 , 0.5647059 , 0.41568628],\n",
       "        ...,\n",
       "        [0.5254902 , 0.42352942, 0.29411766],\n",
       "        [0.6666667 , 0.57254905, 0.4392157 ],\n",
       "        [0.7607843 , 0.6666667 , 0.53333336]],\n",
       "\n",
       "       [[0.83137256, 0.68235296, 0.5058824 ],\n",
       "        [0.8235294 , 0.67058825, 0.50980395],\n",
       "        [0.6509804 , 0.5254902 , 0.3647059 ],\n",
       "        ...,\n",
       "        [0.57254905, 0.4627451 , 0.31764707],\n",
       "        [0.6       , 0.49019608, 0.34509805],\n",
       "        [0.5803922 , 0.46666667, 0.34117648]],\n",
       "\n",
       "       [[0.78039217, 0.6313726 , 0.45490196],\n",
       "        [0.81960785, 0.6666667 , 0.5058824 ],\n",
       "        [0.6745098 , 0.54901963, 0.3882353 ],\n",
       "        ...,\n",
       "        [0.5686275 , 0.4509804 , 0.3019608 ],\n",
       "        [0.58431375, 0.46666667, 0.3254902 ],\n",
       "        [0.627451  , 0.5058824 , 0.38431373]]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image=test_image/255\n",
    "print(test_image.shape)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0.9098039 , 0.827451  , 0.72156864],\n",
       "         [0.85882354, 0.78039217, 0.6745098 ],\n",
       "         [0.7490196 , 0.6313726 , 0.5372549 ],\n",
       "         ...,\n",
       "         [0.5686275 , 0.49019608, 0.39215687],\n",
       "         [0.76862746, 0.6862745 , 0.5803922 ],\n",
       "         [0.77254903, 0.6901961 , 0.58431375]],\n",
       "\n",
       "        [[0.9019608 , 0.81960785, 0.7137255 ],\n",
       "         [0.83137256, 0.7529412 , 0.64705884],\n",
       "         [0.78431374, 0.6666667 , 0.57254905],\n",
       "         ...,\n",
       "         [0.6509804 , 0.57254905, 0.4745098 ],\n",
       "         [0.7490196 , 0.6666667 , 0.56078434],\n",
       "         [0.8392157 , 0.75686276, 0.6509804 ]],\n",
       "\n",
       "        [[0.9137255 , 0.83137256, 0.7254902 ],\n",
       "         [0.81960785, 0.7411765 , 0.63529414],\n",
       "         [0.81960785, 0.7019608 , 0.60784316],\n",
       "         ...,\n",
       "         [0.73333335, 0.654902  , 0.5568628 ],\n",
       "         [0.79607844, 0.7137255 , 0.60784316],\n",
       "         [0.8       , 0.7176471 , 0.6117647 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8352941 , 0.69803923, 0.54901963],\n",
       "         [0.7647059 , 0.627451  , 0.47843137],\n",
       "         [0.7019608 , 0.5647059 , 0.41568628],\n",
       "         ...,\n",
       "         [0.5254902 , 0.42352942, 0.29411766],\n",
       "         [0.6666667 , 0.57254905, 0.4392157 ],\n",
       "         [0.7607843 , 0.6666667 , 0.53333336]],\n",
       "\n",
       "        [[0.83137256, 0.68235296, 0.5058824 ],\n",
       "         [0.8235294 , 0.67058825, 0.50980395],\n",
       "         [0.6509804 , 0.5254902 , 0.3647059 ],\n",
       "         ...,\n",
       "         [0.57254905, 0.4627451 , 0.31764707],\n",
       "         [0.6       , 0.49019608, 0.34509805],\n",
       "         [0.5803922 , 0.46666667, 0.34117648]],\n",
       "\n",
       "        [[0.78039217, 0.6313726 , 0.45490196],\n",
       "         [0.81960785, 0.6666667 , 0.5058824 ],\n",
       "         [0.6745098 , 0.54901963, 0.3882353 ],\n",
       "         ...,\n",
       "         [0.5686275 , 0.4509804 , 0.3019608 ],\n",
       "         [0.58431375, 0.46666667, 0.3254902 ],\n",
       "         [0.627451  , 0.5058824 , 0.38431373]]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "print(test_image.shape)\n",
    "test_image\n",
    "\n",
    "# one 64x64 3 channel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999995]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cnn.predict(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image classified is dog\n"
     ]
    }
   ],
   "source": [
    "if result[0]<=0.5:\n",
    "    print(\"The image classified is cat\")\n",
    "else:\n",
    "    print(\"The image classified is dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
